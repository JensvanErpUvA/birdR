---
title: "aa-processing"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{aa-processing}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


## For Johannes
Sections I think would work as a function are outlines as such:

##################
FUNCTION
Input:
Output:
Short description

<code chunks>

FUNCTION END
##################


#0 Loading packages
Load all required packages for the full post-processing method
```{r load_packages, include=FALSE, echo=FALSE}
library(data.table)     # Functions for creating tables (upgrade of dataframe)
library(lubridate)      # Functions for working with dates and times
library(sf)             # Functions for spatial data manipulations
library(terra)
library(fossil)
library(geosphere)
library(ggplot2)
library(dplyr)
library(mgcv)
```

#1.1 Settings and filenames
Here all required filenames, radar information and processing settings are specified
```{r settings_and_filenames}
## File names
## Bird tracks
radar_filename <- "lud_bird-tracks_bare_w1_06-20.csv"
## Radar masking intensity of the horizontal radar
mask_filename <- "lud_hor_landmask_06-20.csv"
## ERA5 data
ERA5_filename <- "lud_ERA5_10m-windcomp_06-20.csv"
## Turbine locations (all Dutch offshore turbines)
# turbine_filename <- "D:/SURFDrive/R/shapefiles/turbines_en_ohvs.shp"
turbine_filename <- "turbines_en_ohvs.shp"

## General
## Area name
area_name <- "Luchterduinen"
## Start and end time of data (hourly resolution, UTC)
data_start_time <- ymd_hms("2020-06-01 00:00:00", tz="UTC")
data_end_time <- ymd_hms("2020-06-07 23:00:00", tz="UTC")
## Radar coordinates [degrees]
r_lon <- 4.185345
r_lat <- 52.427827
## Projections
wgs84_epsg <- 4326
loc_epsg <- 23095
wgs84_proj <- "+proj=longlat +datum=WGS84 +no_defs "
loc_proj <- "+proj=tmerc +lat_0=0 +lon_0=5 +k=0.9996 +x_0=500000 +y_0=0 +ellps=intl +towgs84=-87,-98,-121,0,0,0,0 +units=m +no_defs"

## Module 1 parameters
## Step 1
## Set the minimum and maximum distance from the radar for reliable bird detection [m]
mid <- 1000
mad <- 2500
## The radar is situated near an offshore windfarm
## Corner of the radar window the turbine blocks the radar
## Corner of overlap between the horizontal and vertical radar (few horizontal-only tracks)
b_corners <- rbind(c(287,30),
                   c(115,135))
## Turbine names (for coordinate extraction from main file)
turbine_names <- "Luchterduinen"
## Turbine mask: circle radius
turb_exclusion_rad <- 100 ## [metres]
## Step 2
## Minimum and maximum airspeed [m/s]
min_airspeed <- 5
max_airspeed <- 30
## Percentiles to visualize for DoT threshold
dot_percs <- seq(0.002,0.02,0.002)

## Module 2 parameters
## Step 3
## Minimum time interval between consequtive observations [s]. 
## This much shorter than the radar rotation speed to allow for differences in observation time (10%)
min_time_inter <- 1.2/10 

## Module 3 parameters
## Step 5
## Resolution of spatial raster for detecting spatial bias [m]
raster_res <- 100
```

#1.1 Data loading and class-converting
Should be user defined as this is highly specific to the user input and requirement. Perhaps there can be an "import function" for uvaRR that converts these variables from character strings automatically, but this is not high-priority
```{r data_loading_and_preprocessing}
## Load in tracking data
tracks_all <- fread(file=radar_filename)

## Data contains two timestamps: the start and end of each track
## Convert timestamps (characters) into POSIXct objects, with timezone = UTC
tracks_all[,timestamp_start := ymd_hms(timestamp_start, tz="UTC")]
tracks_all[,timestamp_end := ymd_hms(timestamp_end, tz="UTC")]

## Convert trajectory into spatial class
tracks_all <- st_as_sf(tracks_all,
                       wkt="trajectory",
                       crs=wgs84_epsg)
tracks_all <- as.data.table(tracks_all)

## Location specific: load in turbines
## Load in turbines
all_turbs <- as.data.table(st_read(turbine_filename))
## Our file contains data for all offshore turbines, so subset to the right wind farm
turbines <- all_turbs[which(all_turbs$NAAM %in% turbine_names),]
rm(all_turbs)
## Convert coordinates into geometry
turbines[,geometry:=st_transform(geometry,crs=wgs84_epsg)]
```

#2.1 Sub-setting based on prior knowledge

##2.1.1 Spatial filtering

We apply the spatial filter by setting up an area of inclusion (AoI) geometry, which will be used to identify tracks outside of it to be removed. Three different filters can be used: 
- inclusion_ring: include region between a minimum and maximum distance from the radar location. 
- exclusion_angle: 
- exclusion_location:

This part is generally required, and setting up the AoI can be adopted into a function (minus the turbines, which is too specific imo). 


```{r min_mad}
area_of_inclusion <-  roi(location= c(r_lon, r_lat),
                          inclusion_donut=c(mad,mid),
                          exclusion_angle=b_corners,
                          exclusion_location=turbines,
                          exclusion_location_buffer=turb_exclusion_rad,
                          crs_loc=loc_epsg)

## Add a tag to the turbines for whether they are in the proximity of the radar (bbox of AoI) mostly for plotting
aoi_bbox <- st_as_sfc(st_bbox(aoi), crs=loc_epsg)
turbines[,near_aoi:=sapply(st_transform(turbines[,geometry],crs=loc_epsg),st_within,y=aoi_bbox, sparse=FALSE)]
```

```{r visualize_inclusion}
ggplot()+
  geom_sf(data=area_of_inclusion, fill="grey", colour="black", lwd = 0.3)+
  # geom_sf(data=st_zm(tracks_step1[,trajectory]), colour="black", lwd = 0.1)+
  geom_sf(data=radar_loc, colour="darkred", shape=16, lwd = 0.7)+
  labs(x="Longitude", y="Latitude", title=area_name)+
  theme_minimal()+
  theme(title = element_text(size=15, face="bold"),
        axis.title = element_text(size=15, face="bold"),
        axis.text = element_text(size=12, face="bold"))
```

This inclusion area can now be used to subset the data
```{r spatial_filter}
## Include all tracks that cross the zone of inclusion
tracks_all[,intersects:=sapply(st_transform(st_zm(trajectory), crs=loc_epsg), st_intersects,
                               y=st_transform(area_of_inclusion, crs=loc_epsg), sparse=FALSE)]

## Filter tracks
tracks_step1 <- tracks_all[intersects==TRUE,]
```

##2.1.2 Biological filtering
We have two track-specific filters

At this point we need to calculate several track parameters
```{r get_parameters}
tracks_step1 <- movement(TRACKS=tracks_step1,
                         VAR=c('n','duration', 'length', 'groundspeed', 'displacement', 'direction','dot'), 
                         crs=loc_epsg)
```

Minimum and maximum airspeed
Firstly we will look at the average airspeed of each track, and filter airspeeds lower and higher than biologically relevant.

```{r add_wind_info}
tracks_step1 <- annotation(TRACKS=tracks_step1,
                           ERA=era,
                           VAR=c("U10m","V10m"),
                           unit="hours")
```

```{r calculate_filter_airspeed}
tracks_step1[,airspeed := mapply(get_airspeed, groundspeed, direction, U10m, V10m)]
tracks_step1 <- tracks_step1[airspeed>=min_airspeed & airspeed<=max_airspeed,]
```

##2.1.3 Non-biological movement

Secondly we identify non-biological movement (low displacement over time, or DoT) which is often related to clutter tracks
The threshold for what DoT is considered too low has to be set manually by the research through visually inspecting the data.

```{r dot_threshold_calculations_visualizations}
dot_perc_vals <- get_dot_percs(track_step1$displacement,track_step1$duration, probs=seq(0.002,0.02,0.002), plot=T)
```

Based on the visualization, a stdp threshold has to be set
```{r set_dot_threshold}
dot_threshold <- dot_perc_vals["1%"]

tracks_step2 <- tracks_step1[dot > dot_threshold,]
```

#2.2 Improving the quality of bird tracks
Erroneous  points exist within some tracks, identifiable by a very short time-interval between those points and the next/previous point. Identify these intervals and remove both points involved with that interval, as there is no way to tell which of these two is faulty

Again here maybe split function between identifying a bad trajectory and fixing it?
Could also be merged: skip returning the true/false and immediatly fix
#############################################
FUNCTION
Input:
- track time per point, as seconds passed since the first point
- time interval threshold
Output:
- TRUE/FALSE of erroneous points
Example: rr_check_error <- function(time_inter, min_time_inter){<code> return(is_erroneous)}
```{r check_trajectories}
## First get the time interval between consequetive points
## Note the time interval between point 1 and point 2 is stored at the second location in the vector (1st is NA)
get_time_inter <- function(trajectory_time){
  n_plots <- length(trajectory_time)
  time_inter <- NA
  time_inter[2:n_plots] <- trajectory_time[2:n_plots]-trajectory_time[1:(n_plots-1)]
  return(time_inter)
}
tracks_step2[,time_inter:=lapply(trajectory_time, get_time_inter)]

## Now check which tracks have an error
check_time_error <- function(time_inter, min_time_inter){
  return(length(which(unlist(time_inter)<=min_time_inter))>0)
}

tracks_step2[,point_error:=sapply(time_inter, 
                                check_time_error,
                                min_time_inter=min_time_inter)]
```

FUNCTION END
#############################################

Now fix the trajectory, as discussed this can be incorporated with the previous function into one function. There are also a lot of posibilities for what to fix: only the trajectoy or all track parameters?
#############################################
FUNCTION
Input:
- trajectory
- track time intervals
Output:
- good trajectory
Example: rr_fix_error <- function(time_inter, min_time_inter){<code> return(is_erroneous)}
```{r fix_trajectories}
## Initialize and run function to get good plots in track
get_good_points <- function(time_inter, min_time_inter){
  ## First find bad points
  error_points <- which(unlist(time_inter) < min_time_inter)
  ## These are the indices of the second point of the two creating the time interval which falls below the threshold 
  ## Collect the indices of the first points
  error_points <- sort(unique(c(error_points-1,error_points)))
  
  ## Gather all indices
  all_points <- 1:length(unlist(time_inter))
  
  ## Now  return the indices minus the errors
  return(all_points[-error_points])
}
tracks_step2[point_error==T, good_points:=lapply(time_inter,
                                              get_good_points,
                                              min_time_inter=min_time_inter)]

## Check if the first or last point was removed
first_last_removed <- function(good_points, nr_of_points){
  return(!(1 %in% good_points & nr_of_points %in% good_points))
}

tracks_step2[point_error==T, first_last_error:= mapply(first_last_removed,
                                                       good_points,
                                                       nr_of_points)]

## Make a function to correct the trajectory
fix_traj <- function(trajectory, good_points){
  new_traj <- st_sfc(st_linestring(st_coordinates(trajectory)[good_points,c("X","Y","Z","M")]), crs=wgs84_epsg)
  return(new_traj)
}
## Correct them
tracks_step2[point_error==T, trajectory := mapply(fix_traj, trajectory, good_points)]
```
FUNCTION END 
#############################################

The other "fix" functions are for track variables other than the trajectory. 
Might be added but have to think whether this info is always available or more RR data specific
``` {r fix_trajectories_extra}
## General fix for vectors
fix_vec <- function(vector, good_points){
  new_vector <- vector[good_points]
  return(list(new_vector))
}

## Fix trajectory timestamps and time interavl
tracks_step2[point_error==T, trajectory_time := mapply(fix_vec, trajectory_time, good_points)]
tracks_step2[point_error==T, time_inter := mapply(fix_vec, time_inter, good_points)]

## If the last plot was among the bad plots, correct some additional properties
## Note: I think I have never seen this happen, so these functions have not been tested extensively
fix_time_end <- function(timestamp_start, trajectory_time){
  new_time_end <- timestamp_start + trajectory_time[length(trajectory_time)]
  return(new_time_end)
}
fix_duration <- function(timestamp_start, timestamp_end){
  duration <- floor(as.numeric(difftime(timestamp_end,timestamp_start, units = "secs")))
  return(duration)
}
fix_str_distance <- function(trajectory, good_points){
  longs <- st_coordinates(trajectory)[c(1,length(good_points)),1]
  lats<- st_coordinates(trajectory)[c(1,length(good_points)),2]
  
  displacement <- deg.dist(longs[1], lats[1], longs[2], lats[2])*1000
  return(displacement)
}
fix_direction <- function(trajectory, good_points){
  longs <- st_coordinates(trajectory)[c(1,length(good_points)),1]
  lats<- st_coordinates(trajectory)[c(1,length(good_points)),2]
  
  direction <- bearingRhumb(c(longs[1], lats[1]), c(longs[2], lats[2]))/180*pi
  return(direction)
}
tracks_step2[point_error==T & first_last_error==T, timestamp_end := mapply(fix_time_end, timestamp_start, trajectory_time)]
tracks_step2[point_error==T & first_last_error==T, duration := mapply(fix_duration, timestamp_start, timestamp_end)]
tracks_step2[point_error==T & first_last_error==T, displacement := mapply(fix_str_distance, trajectory, good_points)]
tracks_step2[point_error==T & first_last_error==T, direction := mapply(fix_direction, trajectory, good_points)]

## Lastly correct some properties that will be changed regardless
tracks_step2[point_error==T, nr_of_points := lengths(good_points)]
tracks_step2[point_error==T, trajectory_length := as.numeric(st_length(st_transform(trajectory, crs=loc_epsg)))]
tracks_step2[point_error==T, groundspeed := trajectory_length/duration]

## Copy tracks for last processing module
tracks_step3 <- tracks_step2
```


#2.3 Removing data sections with negative observation bias
#2.3.1 Detecting temporal NOB

First again some research specific stuff: loadingin and pre-processing our NOB variable. We also use this variable to retrieve which hours the radar was offline.
```{r NOB_variable}
## Initialize all possible hours in the dataset
data_hours <- seq(data_start_time,data_end_time, by="hours")

## Read in our NOB variable: masking data
mask_data <- fread(mask_filename)
## Convert timestamp into POSIXct
mask_data[,timestamp:=ymd_hms(timestamp, tz="UTC")]

## Now create an hourly masking average
mask_hourly <- mask_data[,mean(landmask),by=round_date(timestamp,unit="hours")]
mask_hourly <- setnames(mask_hourly,c("V1","round_date"),c("landmask","timestamp"))

## If we used a temporal subset of the data (for exploration), remove other hours
mask_hourly <- mask_hourly[timestamp %in% data_hours,]

## Use hours in which no filter data is available as tag for offline hours
offline_hours <- data_hours[which(!(data_hours %in% mask_hourly$timestamp))]

## Remove raw dataset
rm(mask_data)
```

Here again room for two functions (or one huge function with use input in between):
- Making an temporal dataset of the data
- Doing a gam analysis and visualizing the result over the data

#############################################
FUNCTION
Input:
- data period start
- data period end
- track data (needs atleast start and end time)
- NOB variable data
- temporal interval
Output:
- temporal dataset with counts of the tracks and average value of the treshold variable per interval
Example: rr_get_temp_data <- function(data_start_time, data_end_time, track_data, nob_variable, "hours"){<code> return(temp_data)}
```{r get_temporal_dataset}
## Initialize all possible hours in the dataset
## Note: this is already done above but should be in the function too
data_hours <- seq(data_start_time, data_end_time, by="hours")

## By calculating the rounded hour of the first, middle, and end timestamp of each track,
## we are nearly certain to cover all hours a track occurs (a true track nearly never last over 3 hours)
## Note: this DOESN'T work if we let the user set the temporal interval!
tracks_step3[,round_hour:=round_date(timestamp_start+0.5*duration,unit="hours")]
tracks_step3[,round_hour_start:=round_date(timestamp_start,unit="hours")]
tracks_step3[,round_hour_end:=round_date(timestamp_end,unit="hours")]

## Create an hourly dataset by looping over the hourly data, and counting
## the number of tracks occuring per hour. Also include information on whether the radar was functioning
## Lastly add the relevant variable affecting negative bias

## Initiate the hourly dataset
hourly_stats <- data.table(timestamp = ymd_hms(),
                           trackcount = integer(),
                           landmask = double(),
                           offline = logical())

## Loop over the hours in this period (note, ALL hours, we also want to loop over moments no tracks are recorded)
for (i in 1:length(data_hours)){
  
  cur_hour <- data_hours[i]
  
  ## Check if radar was offline during this hour
  if (cur_hour %in% offline_hours) {
    off <- TRUE
  } else {
    off <- FALSE
  }
  
  ## Extract the tracks occuring in this hour from the track database
  n_tracks <- nrow(tracks_step3[round_hour == cur_hour |
                                  round_hour_start == cur_hour |
                                  round_hour_end == cur_hour,])
  
  ## Retrieve masking data
  if (cur_hour %in% mask_hourly$timestamp) {
    landmask <- mask_hourly[timestamp == cur_hour,landmask]
  } else {
    landmask <- NA
  }
  ## Now bind all the data as a new row to the hourly_stats
  hourly_stats <- rbind(hourly_stats, list(cur_hour,n_tracks,landmask,off))
}

```

FUNCTION END
#############################################

The second function would do the gam analysis and visualize the gam curve over the data plus 1st/2nd derivative. 
#############################################
FUNCTION
Input:
- temporal dataset with counts of the tracks and average value of the treshold variable per interval
Output:
- visualization of gam relation plus derivative
Example: rr_temp_analysis <- function(temp_data){<code>}
```{r temp_gam_analysis}
## To model the relation between the bias variable and the hourly track count we doe a GAM analysis. 
## Remove the hours the radar was offline
gam_stats <- hourly_stats[offline==FALSE,]

## Set K low (default=9), we want to identify the larger pattern
gam_tempbias <- gam(trackcount ~ s(landmask, k=5),
                    data=gam_stats)

## Visualize the modelled relation on top of the data
## Create response data based on the model
dummy_mask <- seq(min(gam_stats[,landmask]),max(gam_stats[,landmask]),length.out = 100)
response_mask <- as.data.table(predict.gam(gam_tempbias, 
                                           data.frame(landmask = dummy_mask), 
                                           type = "response",
                                           se.fit = T))

## If no clear cut-off is distinguishable, it often helps to visualize the first and 
## second derivative of the response to vind specific turningpoints in the response (onset of decline, max decline) 
d1_response <- c(NA,response_mask$fit[2:100]-response_mask$fit[1:99])
d2_response <- c(NA,d1_response[2:100]-d1_response[1:99])



ggplot()+
  geom_point(data=hourly_stats[offline==FALSE,], aes(x=landmask,y=trackcount),alpha = 1)+
  geom_line(aes(dummy_mask, response_mask$fit), colour="blue", lwd=1)+
  geom_line(aes(dummy_mask, (d1_response*5)), colour="red",lwd=1)+
  geom_line(aes(dummy_mask, (d2_response*50)), colour="purple",lwd=1)+
  xlim(c(0,0.6))+
  theme_minimal()+
  labs(y = "Hourly bird count (#)", x = "Average hourly 'landmask' value (0-1)")+
  theme(axis.title = element_text(size = 14,face = "bold"),
        axis.text = element_text(size = 10,face = "bold"),
        axis.text.y.right = element_text(colour="red"),
        axis.ticks.y.right = element_line(colour="red"),
        axis.title.y.right = element_text(colour="red"))
```

FUNCTION END
#############################################

Now we set the threshold based on the visualizations. Perhaps the next two chunks can be a function, but on the otherhand it is so straightforward it might not be worth it.
```{r set_temp_threshold}
## Set the threshold based on the first derivative 
bias_threshold <- dummy_mask[which(d1_response[3:100]==min(d1_response[3:100]))+1]
```

```{r temp_filter}
## Retrieve hours the threshold was exceeded
threshold_hours <- mask_hourly[landmask > bias_threshold, timestamp]

## Remove tracks occuring completely in hours of high filter activity
tracks_step3 <- tracks_step3[!(round_hour %in% threshold_hours &
                                 round_hour_start %in% threshold_hours &
                                 round_hour_end %in% threshold_hours),]

```

#2.3.2 Detecting spatial bias
############################################
FUNCTION
Input:
- radar location
- maximum distance of inclusion
- track data (trajectories)
- spatial resolution
Output:
- raster which covers the AoI and has track counts and distance from the radar per cell
Note: at the moment the code works with specified lon/lats for setting the raster size. I'd rather have this replaced with the radar location + maximum distance of inclusion (MaD) to set that size.
Example: rr_get_spat_data <- function(radar_loc, mad, track_data, raster_res){<code> return(raster)}
```{r get_spatial_dataset}
track_density_rast <- function(trajectories, loc_proj, r_ext) {
  ## convert track sf's to SpatVector
  traj_vect <- vect(st_zm(trajectories))
  ## local projection
  vect_p <- project(traj_vect,loc_proj)
  
  ## fill in number of raster cells
  numcells <- 1:(dim(r_ext)[1] * dim(r_ext)[2])
  values(r_ext) <- numcells
  
  ## create dataframe with coordinates of extent raster
  r_df <- terra::as.data.frame(r_ext, xy=TRUE)
  
  ## count the number of tracks intersecting with each cell
  r_count <- as.data.table(extract(r_ext, vect_p, xy=TRUE))
  r_count[,cell_num:=1/length(lyr.1), by=ID]
  r_count[,freq:=sum(cell_num), by=lyr.1]
  r_count[,c("ID","cell_num"):=NULL]
  r_count <- unique(r_count, by="lyr.1") %>% 
    left_join(x=r_df, by="lyr.1")
  
  ## if there are zero tracks -> make cell 0 
  r_count[which(is.na(r_count$freq)),"freq"] <- 0
  values(r_ext) <- r_count$freq
  NAflag(r_ext) <- 0
  
  ## Return the raster
  return(r_ext)
}

## Create a raster with the extend surounding the radar space
rast_bbox <- st_bbox(st_transform(st_buffer(st_transform(radar_loc,crs=loc_epsg),mad+2*raster_res),crs=wgs84_epsg))

rast_ext <- rast(xmin=rast_bbox["xmin"], xmax=rast_bbox["xmax"],
                 ymin=rast_bbox["ymin"], ymax=rast_bbox["ymax"],
                 resolution=0.01)
rast_ext <- project(rast_ext, loc_proj)
res(rast_ext) <- raster_res 

track_raster <- project(track_density_rast(tracks_step3[,trajectory], loc_proj=loc_proj, r_ext=rast_ext), wgs84_proj)
set.names(track_raster,"tracks")
```

Visualization of the raster
```{r raster_visualization}
## First visual inspection. Convert the data to a data.frame for plotting. Use the spatial mask set in step 2.1.1 to remove "dead" cells
fig_rast_data <- terra::as.data.frame(mask(track_raster,vect(area_of_inclusion)),xy=TRUE)
setnames(fig_rast_data, c("x","y"),c("lon","lat"))

ggplot()+
  geom_tile(data=fig_rast_data, aes(x=lon,y=lat,fill=tracks))+
  geom_sf(data=area_of_inclusion, fill=NA, colour="black", lwd = 0.3)+
  geom_sf(data=turbines[near_aoi==TRUE,geometry], colour="black", lwd = 0.1)+
  geom_sf(data=radar_loc, colour="darkred", shape=16, lwd = 0.7)+
  scale_fill_gradient(low="grey", high="darkblue", name="Number\n of tracks")+
  labs(x="Longitude", y="Latitude", title=area_name)+
  theme_minimal()+
  theme(title = element_text(size=15, face="bold"),
        axis.title = element_text(size=15, face="bold"),
        axis.text = element_text(size=12, face="bold"))
```

#############################################
FUNCTION
Input:
- raster with counts of the tracks per cell and distance of cell from the radar
Output:
- visualization of gam relation
Example: rr_rast_analysis <- function(raster){<code>}
```{r spatial_gam_analysis}
## Create a layer of distance from the cell to the radar
dist_rast <- distance(rast_ext,project(vect(radar_loc), loc_proj))
dist_rast <- project(dist_rast, wgs84_proj)
set.names(dist_rast,"distance")

add(track_raster) <- dist_rast

rast_data <- as.data.table(terra::as.data.frame(track_raster,xy=TRUE))
setnames(rast_data, c("x","y"), c("lon","lat"))

gam_stats <- rast_data[distance>=mid & distance<=mad,]
gam_distbias <- gam(tracks ~ s(distance),
                     data=gam_stats)

dummy_dist <- seq(mid,mad,length.out = 1000)
response_dist <- as.data.table(predict.gam(gam_distbias, 
                                            data.frame(distance = dummy_dist), 
                                            type = "response",
                                            se.fit = T))
## TODO get the confidence interval of the gam.prediction

ggplot()+
  geom_point(data = gam_stats, aes(x=distance,y=tracks))+
  geom_ribbon(aes(x=dummy_dist,ymin=(response_dist$fit-10*response_dist$se.fit),
  ymax=(response_dist$fit+10*response_dist$se.fit)), colour = NA, fill = "purple", alpha = 0.4)+
  geom_line(aes(x=dummy_dist,y=response_dist$fit), colour = "purple", lwd=1)+
  theme_minimal()+
  theme(legend.text = element_text(size=15, face="bold"),
        legend.title = element_text(size=15, face="bold"),
        axis.title = element_text(size=20, face="bold"),
        axis.text = element_text(size=15, face="bold"))
```

FUNCTION END
#############################################

Lastly, the spatial threshold should be set. This is based on the visualization of the gam again. In our example the gam curve itself is used to set the threshold. Here it is a bit more complicated to retrieve which cells cross the threshold. However I don't know how useful a function for this would be still.

```{r set_spat_threshold}
rast_data[distance>=mid & distance<=mad,
          threshold_tracks:=predict.gam(gam_distbias,distance=rast_data$distance,type="response")]
rast_data[,inclusion_cell:=tracks>=threshold_tracks]
rast_data[is.na(threshold_tracks),inclusion_cell:=T]

fig_rast_data <- as.data.table(as.data.frame(mask(rast(rast_data, type="xyz", crs=wgs84_proj),vect(area_of_inclusion)),xy=TRUE))
setnames(fig_rast_data, c("x","y"), c("lon","lat"))

ggplot()+
  geom_tile(data=fig_rast_data[inclusion_cell==TRUE,], aes(x=lon,y=lat,fill=tracks))+
  geom_sf(data=area_of_inclusion, fill=NA, colour="black", lwd = 0.3)+
  geom_sf(data=turbines[near_aoi==TRUE,geometry], colour="black", lwd = 0.1)+
  geom_sf(data=radar_loc, colour="darkred", shape=16, lwd = 0.7)+
  scale_fill_gradient(low="grey", high="darkblue", name="Number\n of tracks", limits=c(0,max(fig_rast_data[inclusion_cell==T,tracks])))+
  labs(x="Longitude", y="Latitude", title=area_name)+
  theme_minimal()+
  theme(legend.text = element_text(size=15, face="bold"),
        legend.title = element_text(size=15, face="bold"),
        axis.title = element_text(size=20, face="bold"),
        axis.text = element_text(size=15, face="bold"))

setnames(rast_data, c("lon","lat"), c("x","y"))
track_raster <- rast(rast_data, type="xyz", crs=wgs84_proj)


crosses_aoi <- function(trajectory, raster) {
  ## convert track sf's to SpatVector
  traj_vect <- vect(st_zm(trajectory))
  
  ## Get the cells with which the trajectory overlaps
  overlap <- extract(raster, traj_vect, xy=TRUE)
  
  return(any(overlap$inclusion_cell==1))
}

tracks_step3[,crosses_raster:=sapply(trajectory,crosses_aoi,raster=track_raster)]
```

Now filter based on whether a track is intersecting the raster

```{r spatial_filter}
tracks_final <- tracks_step3[within_raster==TRUE,]
```

Done!
